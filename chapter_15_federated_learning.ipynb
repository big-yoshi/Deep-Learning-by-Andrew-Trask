{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "import sys\n",
    "from chp13 import *\n",
    "np.random.seed(12345)\n",
    "\n",
    "# dataset from http://www2.aueb.gr/users/ion/data/enron-spam/\n",
    "\n",
    "import codecs\n",
    "with codecs.open('data/spam.txt', \"r\",encoding='utf-8', errors='ignore') as fdata:\n",
    "    raw = fdata.readlines()\n",
    "\n",
    "vocab = set()\n",
    "    \n",
    "spam = list()\n",
    "for row in raw:\n",
    "    spam.append(set(row[:-2].split(\" \")))\n",
    "    for word in spam[-1]:\n",
    "        vocab.add(word)\n",
    "    \n",
    "import codecs\n",
    "with codecs.open('data/ham.txt', \"r\",encoding='utf-8', errors='ignore') as fdata:\n",
    "    raw = fdata.readlines()\n",
    "\n",
    "ham = list()\n",
    "for row in raw:\n",
    "    ham.append(set(row[:-2].split(\" \")))\n",
    "    for word in ham[-1]:\n",
    "        vocab.add(word)\n",
    "        \n",
    "vocab.add(\"<unk>\")\n",
    "\n",
    "vocab = list(vocab)\n",
    "w2i = {}\n",
    "for i,w in enumerate(vocab):\n",
    "    w2i[w] = i\n",
    "    \n",
    "def to_indices(input, l=500):\n",
    "    indices = list()\n",
    "    for line in input:\n",
    "        if(len(line) < l):\n",
    "            line = list(line) + [\"<unk>\"] * (l - len(line))\n",
    "            idxs = list()\n",
    "            for word in line:\n",
    "                idxs.append(w2i[word])\n",
    "            indices.append(idxs)\n",
    "    return indices\n",
    "            \n",
    "spam_idx = to_indices(spam)\n",
    "ham_idx = to_indices(ham)\n",
    "\n",
    "train_spam_idx = spam_idx[0:-1000]\n",
    "train_ham_idx = ham_idx[0:-1000]\n",
    "\n",
    "test_spam_idx = spam_idx[-1000:]\n",
    "test_ham_idx = ham_idx[-1000:]\n",
    "\n",
    "train_data = list()\n",
    "train_target = list()\n",
    "\n",
    "test_data = list()\n",
    "test_target = list()\n",
    "\n",
    "for i in range(max(len(train_spam_idx),len(train_ham_idx))):\n",
    "    train_data.append(train_spam_idx[i%len(train_spam_idx)])\n",
    "    train_target.append([1])\n",
    "    \n",
    "    train_data.append(train_ham_idx[i%len(train_ham_idx)])\n",
    "    train_target.append([0])\n",
    "    \n",
    "for i in range(max(len(test_spam_idx),len(test_ham_idx))):\n",
    "    test_data.append(test_spam_idx[i%len(test_spam_idx)])\n",
    "    test_target.append([1])\n",
    "    \n",
    "    test_data.append(test_ham_idx[i%len(test_ham_idx)])\n",
    "    test_target.append([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, input_data, target_data, batch_size=500, iterations=5):\n",
    "    \n",
    "    criterion = MSELoss()\n",
    "    optim = SGD(parameters=model.get_parameters(), alpha=0.01)\n",
    "    \n",
    "    n_batches = int(len(input_data) / batch_size)\n",
    "    for iter in range(iterations):\n",
    "        iter_loss = 0\n",
    "        for b_i in range(n_batches):\n",
    "\n",
    "            # padding token should stay at 0\n",
    "            bs = batch_size\n",
    "            model.weight.data[w2i['<unk>']] *= 0 \n",
    "            input = Tensor(input_data[b_i*bs:(b_i+1)*bs], autograd=True)\n",
    "            target = Tensor(target_data[b_i*bs:(b_i+1)*bs], autograd=True)\n",
    "\n",
    "            pred = model.forward(input).sum(1).sigmoid()\n",
    "            loss = criterion.forward(pred,target)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "            iter_loss += loss.data[0] / bs\n",
    "\n",
    "            sys.stdout.write(\"\\r\\tLoss:\" + str(iter_loss / (b_i+1)))\n",
    "        print()\n",
    "    return model\n",
    "\n",
    "def test(model, test_input, test_output):\n",
    "    \n",
    "    model.weight.data[w2i['<unk>']] *= 0 \n",
    "    \n",
    "    input = Tensor(test_input, autograd=True)\n",
    "    target = Tensor(test_output, autograd=True)\n",
    "\n",
    "    pred = model.forward(input).sum(1).sigmoid()\n",
    "    return ((pred.data > 0.5) == target.data).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLoss:0.037140416860871446\n",
      "% Correct on Test Set: 98.65\n",
      "\tLoss:0.011258669226059114\n",
      "% Correct on Test Set: 99.15\n",
      "\tLoss:0.008068268387986223\n",
      "% Correct on Test Set: 99.45\n"
     ]
    }
   ],
   "source": [
    "model = Embedding(vocab_size=len(vocab), dim=1)\n",
    "model.weight.data *= 0\n",
    "criterion = MSELoss()\n",
    "optim = SGD(parameters=model.get_parameters(), alpha=0.01)\n",
    "\n",
    "for i in range(3):\n",
    "    model = train(model, train_data, train_target, iterations=1)\n",
    "    print(\"% Correct on Test Set: \" + \\\n",
    "          str(test(model, test_data, test_target)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lets make it federated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bob = (train_data[0:1000], train_target[0:1000])\n",
    "alice = (train_data[1000:2000], train_target[1000:2000])\n",
    "sue = (train_data[2000:], train_target[2000:])\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training Round\n",
      "\tStep 1: send the model to bob\n",
      "\tLoss:0.007924345075144994\n",
      "\n",
      "\tStep 2: send the model to alice\n",
      "\tLoss:0.007990960300900699\n",
      "\n",
      "\tStep 3: send the model to sue\n",
      "\tLoss:0.0063886639830050015\n",
      "\n",
      "\tAverage everyones new models\n",
      "\t% Correct on Test set: 99.5\n",
      "Starting Training Round\n",
      "\tStep 1: send the model to bob\n",
      "\tLoss:0.007331416633817908\n",
      "\n",
      "\tStep 2: send the model to alice\n",
      "\tLoss:0.007292494659027588\n",
      "\n",
      "\tStep 3: send the model to sue\n",
      "\tLoss:0.0060201301162778244\n",
      "\n",
      "\tAverage everyones new models\n",
      "\t% Correct on Test set: 99.6\n",
      "Starting Training Round\n",
      "\tStep 1: send the model to bob\n",
      "\tLoss:0.006884940668687032\n",
      "\n",
      "\tStep 2: send the model to alice\n",
      "\tLoss:0.006776291525625332\n",
      "\n",
      "\tStep 3: send the model to sue\n",
      "\tLoss:0.0056944688964336195\n",
      "\n",
      "\tAverage everyones new models\n",
      "\t% Correct on Test set: 99.65\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"Starting Training Round\")\n",
    "    print(\"\\tStep 1: send the model to bob\")\n",
    "    bob_model = train(copy.deepcopy(model),bob[0],bob[1],iterations=1)\n",
    "    \n",
    "    print(\"\\n\\tStep 2: send the model to alice\")\n",
    "    alice_model = train(copy.deepcopy(model),\n",
    "                       alice[0], alice[1], iterations=1)\n",
    "    \n",
    "    print(\"\\n\\tStep 3: send the model to sue\")\n",
    "    sue_model = train(copy.deepcopy(model),sue[0],sue[1], iterations=1)\n",
    "    \n",
    "    print(\"\\n\\tAverage everyones new models\")\n",
    "    model.weight.data = (bob_model.weight.data + alice_model.weight.data+\n",
    "                        sue_model.weight.data) / 3\n",
    "    print(\"\\t% Correct on Test set: \"+\n",
    "         str(test(model,test_data,test_target) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
